# Neural Network Observation Matching and Processing Pipeline

## Summary: Neural Network Observation Matching and Processing Pipeline

This document summarizes the complete process needed to achieve exact matching between 
the neural network predictions and recorded rollout data for the F-16 SafeRL rejoin task.

## 1. State Vector Structure & Indices

**Problem**: Initially using wrong state indices - had swapped position indices and wrong offsets.

**Solution**: Used correct indices from `SafeRL/saferl/aerospace/models/f16/aerobench/util.py`:

```python
VT = 0        # Velocity
PSI = 5       # Heading angle (yaw)
POS_N = 9     # North position  
POS_E = 10    # East position
# Wingman aircraft: add +16 offset to all indices
```

**Key Discovery**: The rollout.mat stores two complete F-16 state vectors (38 total states):
- Lead aircraft: indices 0-12 (13 states)
- Wingman aircraft: indices 16-28 (13 states, +16 offset)

## 2. Coordinate System & Heading Conversion

**Problem**: PSI angle in F-16 model vs. standard mathematical heading.

**Solution**: Convert PSI to standard heading:

```python
lead_heading = np.pi/2 - lead_psi
wing_heading = np.pi/2 - wing_psi
```

This transforms from:
- **PSI**: Aviation convention (0° = North, clockwise positive)
- **Standard heading**: Math convention (0° = East, counterclockwise positive)

## 3. Observation Processing: DubinsObservationProcessor with "magnorm" Mode

The key insight was understanding the **magnitude-normalized** representation:

### vec2magnorm Function:

```python
def vec2magnorm(vec):
    norm = np.linalg.norm(vec)
    if norm < 1e-6:
        return np.array([0, 0, 0])
    return np.concatenate(([norm], vec / norm))
```

Converts 2D vector `[x, y]` → `[magnitude, x/norm, y/norm]`

### Observation Components (12 values total):

1. **Wingman→Lead relative position** (3 values): `[1.0, dir_x, dir_y]`
2. **Wingman→Rejoin region relative position** (3 values): `[1.0, dir_x, dir_y]`  
3. **Wingman velocity** (3 values): `[1.0, dir_x, dir_y]`
4. **Lead velocity** (3 values): `[1.0, dir_x, dir_y]`

## 4. Critical Processing Steps

### Step 1: Extract Positions & Velocities

```python
lead_pos = np.array([state[POS_E], state[POS_N]])
wing_pos = np.array([state[POS_E + 16], state[POS_N + 16]])
lead_vel = lead_speed * [cos(lead_heading), sin(lead_heading)]
wing_vel = wing_speed * [cos(wing_heading), sin(wing_heading)]
```

### Step 2: Compute Rejoin Region

```python
rejoin_offset_dist = 500  # From config: r_offset
rejoin_angle = lead_heading - np.deg2rad(180 - 60)  # aspect_angle: 60°
rejoin_pos = lead_pos + 500 * [cos(rejoin_angle), sin(rejoin_angle)]
```

### Step 3: Transform to Wingman's Reference Frame

```python
# Rotation matrix using wingman's heading
c, s = np.cos(wing_heading), np.sin(wing_heading)
R = np.array([[c, -s], [s, c]])

# Rotate all vectors to wingman's frame
wingman_lead_r = R.T @ (lead_pos - wing_pos)
wingman_rejoin_r = R.T @ (rejoin_pos - wing_pos)
wing_vel_rotated = R.T @ wing_vel
lead_vel_rotated = R.T @ lead_vel
```

### Step 4: Apply vec2magnorm & Force Magnitude=1.0

```python
# Convert to magnorm format but force magnitudes to 1.0
# (This is how the training data was normalized)
obs = np.array([
    1.0, wingman_lead_r_norm[1], wingman_lead_r_norm[2],
    1.0, wingman_rejoin_r_norm[1], wingman_rejoin_r_norm[2], 
    1.0, wing_vel_norm[1], wing_vel_norm[2],
    1.0, lead_vel_norm[1], lead_vel_norm[2]
])
```

## 5. Network Action Processing

### Raw Network Output: 
4 values from ONNX model

### Action Extraction: 
Uses indices 0 and 2 (not 0 and 1!)

```python
heading_output = np.clip(action[0][0], -1, 1)
velocity_output = np.clip(action[0][2], -1, 1)  # Note: index 2!
```

### Scaling to Physical Units:

```python
heading_change = heading_output * 0.174533  # ±10° in radians
velocity_change = velocity_output * 10.0     # ±10 ft/s
```

## 6. Verification Results

**Before fixes**: Large mismatches, wrong state extraction
**After fixes**: Exact matches to numerical precision:

- **Step 0**: ✓ All 12 observation values match eval.log
- **Step 1**: ✓ All 12 observation values match eval.log  
- **Step 5**: ✓ Network vs actual actions:
  - Heading: 0.000000 difference
  - Velocity: 0.000002 difference

## 7. Key Technical Insights

1. **magnorm representation**: Normalizes direction while preserving magnitude info
2. **Reference frame rotation**: All observations in wingman's body frame
3. **Rejoin region geometry**: 500ft behind lead, offset by 60° aspect angle
4. **Action indexing**: Network outputs 4 values but only uses indices [0,2]
5. **Coordinate conventions**: Careful PSI→heading conversion essential
6. **State vector layout**: 38 states = 2 aircraft × 13 states each + gaps

## 8. Files Created/Modified

### Core Scripts:
- `verify_observation.py` - Validates observation processing against eval.log
- `debug_step5.py` - Debugs specific step mismatches  
- `plot_rollout_2d_interactive.py` - Interactive visualization with validation

### Key Functions:
- `get_observation(state)` - Converts state to normalized observation
- `vec2magnorm(vec)` - Magnitude-normalized vector representation
- `get_network_action(obs)` - Neural network inference with proper scaling

## Conclusion

This pipeline successfully recreates the exact observation processing used during SafeRL 
training, enabling perfect validation of the neural network against recorded flight data. 
The key was understanding the magnitude-normalized representation, correct state indexing, 
coordinate transformations, and proper action scaling. 
